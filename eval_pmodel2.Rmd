---
title: "eval_pmodel"
author: "Beni Stocker"
date: "`r Sys.Date()`"
# output:
#   html_document:
#     toc: true
#     toc_float: true
#     toc_depth: 4
#     number_sections: true
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
header-includes:
   - \usepackage{amsmath}
bibliography: bibliography.bib
---


## Load libraries etc.

```{r "knitr config", cache = FALSE, include=FALSE}
require(knitr)
library(rsofun)
library(rbeni)
library(cowplot)
source("filter_days.R")
source("extract_metric_oob.R")
source("create_table_latex.R")
source("getrow_statstable.R")
load_dependencies_rsofun()
systr <- "''"    # for Mac
# systr <- ""      # for Linux
```


## Load settings

```{r}
## Calibration settings from FULL
load("./data/settings_calib_FULL.Rdata")
load("./data/settings_eval_FULL.Rdata")
load("./data/settings_sims_FULL.Rdata")
load("./data/mod_FULL.Rdata")
```

## Load data

Load evaluation data if not available.
```{r}
if (!exists("out_eval_ORG"))          load( "~/eval_pmodel/calib_results/out_eval_ORG.Rdata")
if (!exists("out_eval_BRC"))          load( "~/eval_pmodel/calib_results/out_eval_BRC.Rdata")
if (!exists("out_eval_FULL"))         load( "~/eval_pmodel/calib_results/out_eval_FULL.Rdata")
if (!exists("out_eval_FULL_FPARitp")) load( "~/eval_pmodel/calib_results/out_eval_FULL_FPARitp.Rdata")
if (!exists("out_eval_FULL_EVI"))     load( "~/eval_pmodel/calib_results/out_eval_FULL_EVI.Rdata")
if (!exists("out_eval_DT"))           load( "~/eval_pmodel/calib_results/out_eval_FULL_DT.Rdata")
if (!exists("out_eval_NTsub"))        load( "~/eval_pmodel/calib_results/out_eval_FULL_NTsub.Rdata")
if (!exists("out_eval_Ty"))           load( "~/eval_pmodel/calib_results/out_eval_FULL_Ty.Rdata")
``` 


# Evaluation of GPP against FLUXNET data

## Sites overview map and table

Get calibration and evaluation sites.
```{r}
evalsites <- settings_eval$sitenames
missing_mod <- purrr::map_lgl( mod$daily, ~identical(., NA ) ) %>% which() %>% names()
evalsites <- evalsites[which(!(evalsites %in% missing_mod))]

calibsites <- settings_calib$sitenames
```


Creating Figure 1 for paper. Showing sites used for the model evaluation are shown on a map. 

```{r siteoverview_fig, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
require(ncdf4, quietly = TRUE)
ncfiln <- "~/data/greve/ep_over_p_cru_ncep.nc"
if (!file.exists(ncfiln)) {
  epop <- array( 1, dim=c(720,360) )
} else {
  nc <- nc_open( ncfiln )
  epop <- ncvar_get( nc, varid="EP_OVER_P_CRU_NCEP" )
}


# source("plot_map_siteoverview.R")
# sites_used_ddf <- out_eval_FULL$gpp$fluxnet2015$data$ddf$sitename %>% unique()
# identical( settings_eval$sitenames, sites_used_ddf )
# siteinfo <- dplyr::filter( metainfo_Tier1_sites_kgclimate_fluxnet2015, sitename %in% sites_used_ddf )
# 
# plot_map_siteoverview( siteinfo, 1/epop, plotfiln="./fig/map_sites.pdf" )
# plot_map_siteoverview( siteinfo, 1/epop )

df_calibsites <- metainfo_Tier1_sites_kgclimate_fluxnet2015 %>% 
  dplyr::filter( sitename %in% calibsites )
df_evalsites <- metainfo_Tier1_sites_kgclimate_fluxnet2015 %>% 
  dplyr::filter( sitename %in% evalsites & !(sitename %in% calibsites) )

gg <- plot_map3(
  1/epop, 
  breaks = c(0,0.2,0.3,0.4,0.5,0.7,1,1.3,1.6,2,2.5,3,Inf), 
  colorscale = c( "royalblue3", "wheat", "tomato" ) %>% rev(), 
  combine = FALSE,
  legend_title = "P/PET" 
  )

gg$ggmap <- gg$ggmap +
  geom_point( data = df_evalsites, aes(x = lon, y = lat), col='black', pch=19, bg='black', size=1.2 ) +
  geom_point( data = df_calibsites, aes(x = lon, y = lat), col='black', pch=21, bg='springgreen2', size=2 )

cowplot::plot_grid(gg$ggmap, gg$gglegend, ncol = 2, rel_widths = c(1, 0.2))

ggsave("./fig/map_sites.pdf", width = 7, height = 4)

# cap_siteoverview_fig <- fig_nums( "siteoverview_fig", caption=" Geographical distribution of sites selected for the bias evaluation. Sites listed in Table S1 as group 1 are in green, sites of group 2 are in black. The color of land area represents aridity, quantified as the ratio of potential evapotranspiration over precipitation from xxx" )
```

Creating an overview table for the Appendix.


## Sites per climate zone

Creating Table 2 for paper showing number of sites per climate zone. 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE}
## determine which zones to plot
sites_used <- out_eval_FULL$gpp$fluxnet2015$data$ddf$sitename %>% unique()
df_zones_used <- rsofun::metainfo_Tier1_sites_kgclimate_fluxnet2015 %>% 
  dplyr::filter( sitename %in% sites_used ) %>% 
  mutate( hemisphere = ifelse( lat>0, "north", "south" ) ) %>% 
  group_by( koeppen_code, hemisphere ) %>%
  summarise( nsites = n() ) %>% 
  filter(nsites > 3) %>%
  left_join( dplyr::rename( rsofun::koeppen_legend, koeppen_code = Code ), by = "koeppen_code" )%>%
  arrange( -nsites ) %>% 
  mutate(climatezone = paste(koeppen_code, hemisphere)) %>% 
  filter(!(koeppen_code=="ET")) %>% 
  ungroup()

df_rosetta <- tibble(
  climatezone = c("Aw south", "BSk north", "Cfa north", "Cfb north", "Cfb south", "Csa north", "Csb north", "Dfb north", "Dfc north", "ET"),
  label = c("Tropical savannah, dry winter, SH", "Arid steppe, cold", "Warm tem., fully humid, hot summer", "Warm tem., fully humid, warm summer",
    "Warm tem., fully humid, warm summer, SH", "Warm tem., dry and hot summer", "Warm tem., dry and warm summer", "Cold, fully humid, warm summer", 
    "Cold, fully humid, cold summer", "Polar tundra" )  )

save(df_rosetta, file = "./data/df_rosetta.Rdata")

list_rosetta <- c(
  "Aw south"  = "Tropical savannah, dry winter, SH", 
  "BSk north" = "Arid steppe, cold", 
  "Cfa north" = "Warm tem., fully humid, hot summer", 
  "Cfb north" = "Warm tem., fully humid, warm summer",
  "Cfb south" = "Warm tem., fully humid, warm summer, SH", 
  "Csa north" = "Warm tem., dry and hot summer", 
  "Csb north" = "Warm tem., dry and warm summer", 
  "Dfb north" = "Cold, fully humid, warm summer", 
  "Dfc north" = "Cold, fully humid, cold summer", 
  "ET"        = "Polar tundra")

getname_climatezone <- function(myclimatezone){
  load("./data/df_rosetta.Rdata")
  df_rosetta %>% 
    dplyr::filter(climatezone==myclimatezone) %>% 
    dplyr::select(label) %>% 
    unlist()
}

df_zones_used %>% 
  xtable::xtable( caption = "Caption text", auto = TRUE ) %>%
  print( hline.after=c(-1, 0), file = "./tab/table_nsites_kgclimate.tex" )
```

## Get NULL model

Fit the NULL with constant and spatially uniform LUE. 

Assume that light use efficiency (LUE) is constant and GPP is calculated as:
$$
\text{GPP} = \text{fAPAR} \times \text{PAR} \times \text{LUE}  
$$
LUE is a constant and is calibrated, given GPP data (here based on the nighttime decomposition method). fAPAR is splined MODIS FPAR MCD15A3H.

**Important:**  Make sure that the fAPAR files are splined MODIS FPAR before collecting respective data with `get_obs_eval()`.

```{r, eval=TRUE, message=FALSE, warning=FALSE}
filn <- "~/eval_pmodel/data/obs_eval_NT_WITHFORCING.Rdata"
settings_eval$benchmark <- list(gpp = "fluxnet2015_NT")
overwrite <- TRUE

if (file.exists(filn) && !overwrite){
  load(filn)
} else {
  obs_eval_NT  <- get_obs_eval( 
    settings_eval = settings_eval, 
    settings_sims = settings_sims, 
    overwrite = TRUE, 
    light = TRUE,
    add_forcing = TRUE
  )
  save(obs_eval_NT, file = filn)
}  

mod_NULL <- obs_eval_NT$ddf %>% 
            dplyr::select( sitename, date, gpp_obs = gpp, ppfd_fluxnet2015, fapar ) %>% 
            mutate( apar = ppfd_fluxnet2015 * fapar ) %>% 
            mutate( gpp_obs = ifelse( date < "2000-02-18", NA, gpp_obs ) ) 

## to fit constant LUE, fit linear model with zero intercept and just use its coefficient (slope)
linmod <- lm( gpp_obs ~ 0 + apar, data = filter(mod_NULL, sitename %in% calibsites) )
save(linmod, file="data/linmod_NULL.RData")
mod_NULL <- mod_NULL %>% 
  dplyr::filter(sitename %in% evalsites) %>% 
  dplyr::select( sitename, date, apar ) %>%
  mutate( gpp = coef(linmod) * apar ) %>%
  dplyr::select( -apar )

## change the structure to something like the one of mod_FULL and mod_RED
mod_NULL <- list(daily = mod_NULL)
save(mod_NULL, file = "./data/mod_NULL.Rdata")

settings_eval$sitenames <- evalsites

## evaluate NULL simulations
if (!file.exists("data/out_eval_NULL.Rdata") || overwrite){
  out_eval_NULL <- eval_sofun( mod_NULL, settings_eval, settings_sims, obs_eval = obs_eval_NT, overwrite = TRUE )
  save( out_eval_NULL, file = "calib_results/out_eval_NULL.Rdata" )
} else {
  if (!exists("out_eval_NULL")) load("calib_results/out_eval_NULL.Rdata")
}
row_rsqtable_NULL <- bind_cols( Setup = "NULL", getrow_statstable( out_eval_NULL, stat = "rsq" ) )
```


## Metrics tables

Create a latex table for $R^2$ and RMSE:
```{r, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
source("create_table_latex.R")

table_rsq <- bind_rows( 
  bind_cols( Setup = "FULL",         dplyr::select( getrow_statstable( out_eval_FULL, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "BRC",          dplyr::select( getrow_statstable( out_eval_BRC, stat = "rsq" ),  xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "ORG",          dplyr::select( getrow_statstable( out_eval_ORG, stat = "rsq" ),  xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "NULL",         dplyr::select( getrow_statstable( out_eval_NULL, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_FPARitp", dplyr::select( getrow_statstable( out_eval_FULL_FPARitp, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_EVI",     dplyr::select( getrow_statstable( out_eval_FULL_EVI, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_DT",      dplyr::select( getrow_statstable( out_eval_DT, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_NTsub",   dplyr::select( getrow_statstable( out_eval_NTsub, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_Ty",      dplyr::select( getrow_statstable( out_eval_Ty, stat = "rsq" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) )
  ) %>% 
  rename_( "8-daily"="xdaily", "Spatial"="spatial", "Annual"="annual", "Seasonal"="seasonal", "var(daily)"="daily_var", "var(annual)"="annual_var") %>%
  create_table_latex( caption = "Caption text", filn = "./tab/table_rsq.tex" )

table_rmse <- bind_rows( 
  bind_cols( Setup = "FULL",         dplyr::select( getrow_statstable( out_eval_FULL, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "BRC",          dplyr::select( getrow_statstable( out_eval_BRC, stat = "rmse" ),  xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "ORG",          dplyr::select( getrow_statstable( out_eval_ORG, stat = "rmse" ),  xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "NULL",         dplyr::select( getrow_statstable( out_eval_NULL, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_FPARitp", dplyr::select( getrow_statstable( out_eval_FULL_FPARitp, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_EVI",     dplyr::select( getrow_statstable( out_eval_FULL_EVI, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_DT",      dplyr::select( getrow_statstable( out_eval_DT, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_NTsub",   dplyr::select( getrow_statstable( out_eval_NTsub, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) ),
  bind_cols( Setup = "FULL_Ty",      dplyr::select( getrow_statstable( out_eval_Ty, stat = "rmse" ), xdaily, spatial, annual, seasonal, daily_var, annual_var ) )
  ) %>% 
  rename_( "8-daily"="xdaily", "Spatial"="spatial", "Annual"="annual", "Seasonal"="seasonal", "var(daily)"="daily_var", "var(annual)"="annual_var") %>%
  create_table_latex( caption = "Caption text", filn = "./tab/table_rmse.tex" )
```



## X-daily values (Fig. 2)

Ignoring that we don't expect a LUE-type linear relationship between absorbed light $I_{\text{abs}}$ and GPP, we can still evaluate the daily GPP estimated by the P-model:
$$
\text{GPP}(d) = \text{LUE}(m|d)\; \times \; I_{\text{abs}}(d)
$$
Here, $LUE(m|d)$ is the monthly varying light use efficiency simulated by the P-model using forcing data averaged to monthly means. $m|d$ refers to the month of a given day.

The correlation is still quite good...

```{r, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
# source("plot_modobs.R")

## Figure 2
  dir_figs <- "./fig/"
  if (!dir.exists(dir_figs)) system( paste0( "mkdir -p ", dir_figs))
  
  ## get stats and plot
  modobs_xdf_FULL <- analyse_modobs2(
    out_eval_FULL$gpp$fluxnet2015$data$xdf,
    "gpp_mod",
    "gpp_obs",
    type = "heat"
    )
  modobs_xdf_NULL <- analyse_modobs2(
    out_eval_NULL$gpp$fluxnet2015$data$xdf,
    "gpp_mod",
    "gpp_obs",
    type = "heat"
    )  
  
  ## print plot
  gg_FULL <- modobs_xdf_FULL$gg +
    labs(x = expression( paste("simulated GPP (gC m"^-2, " d"^-1, ")" ) ), 
         y = expression( paste("observed GPP (gC m"^-2, " d"^-1, ")" ) ),
         title = "FULL") +
    xlim(0, 20) +
    ylim(0, 20)
  gg_NULL <- modobs_xdf_NULL$gg +
    labs(x = expression( paste("simulated GPP (gC m"^-2, " d"^-1, ")" ) ), 
         y = expression( paste("observed GPP (gC m"^-2, " d"^-1, ")" ) ),
         title = "NULL") +
    xlim(0, 20) +
    ylim(0, 20)
  
  ## arrange
  cowplot::plot_grid(gg_FULL, gg_NULL, labels = "auto", label_size = 12)
  
  filn <- paste0( dir_figs, "/modobs_xdaily.pdf" )
  ggsave(filn, width=10, height=5)  
```


## Spatial/annual (Fig. 3)

This shows the same as in the SI of our submitted manuscript: Figures S14 and S15 [here](http://rpubs.com/stineb/si_soilm_global).

```{r, echo=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
## Use customized plotting
source("plot_modobs_spatial_annual2.R")

gg_FULL     <- plot_modobs_spatial_annual2(out_eval_FULL)
gg_NULL     <- plot_modobs_spatial_annual2(out_eval_NULL)
gg_FULL_EVI <- plot_modobs_spatial_annual2(out_eval_FULL_EVI)

gg_FULL <- gg_FULL +
  labs(title = "FULL", 
       y = expression( paste("observed GPP (gC m"^-2, "yr"^-1, ")" ) ), 
       x = expression( paste("simulated GPP (gC m"^-2, "yr"^-1, ")" ) )
      ) +
  xlim(0, 4000) + ylim(0, 4000)
  
gg_NULL <- gg_NULL +
  labs(title = "NULL", 
       x = expression( paste("observed GPP (gC m"^-2, " yr"^-1, ")" ) ), 
       y = expression( paste("simulated GPP (gC m"^-2, " yr"^-1, ")" ) )
      ) +
  xlim(0, 4000) + ylim(0, 4000)

gg_FULL_EVI <- gg_FULL_EVI +
  labs(title = "FULL_EVI", 
       x = expression( paste("observed GPP (gC m"^-2, " yr"^-1, ")" ) ), 
       y = expression( paste("simulated GPP (gC m"^-2, " yr"^-1, ")" ) )
      ) +
  xlim(0, 4000) + ylim(0, 4000)

cowplot::plot_grid(gg_FULL, gg_NULL, gg_FULL_EVI, labels = "auto", label_size = 12)
  
filn <- paste0( dir_figs, "modobs_spatial_annual.pdf" )
ggsave(filn, width=10.3, height=10.3)  
```

<!-- And for individual sites (not shown in paper):
```{r}
source("plot_linmod.R")
## different GPP data (NT, DT)
purrr::map(
  as.list(out_eval_DT$data$adf_stats$sitename),
  ~plot_linmod(
    out_eval_DT$data$adf_stats$data[ which(out_eval_DT$data$adf_stats$sitename==.) ][[1]],
    df2 = out_eval_NTsub$data$adf_stats$data[ which(out_eval_NTsub$data$adf_stats$sitename==.) ][[1]],
    df3 = NULL, #out_eval_Ty$data$adf_stats$data[ which(out_eval_Ty$data$adf_stats$sitename==.) ][[1]],
    xlim = c(0,4000), ylim = c(0,4000),
    sitename = .,
    fitted = NA,
    label = "DT_NT"
  )
)
## different greenness data
purrr::map(
  as.list(out_eval_FULL$gpp$fluxnet2015$data$adf_stats$sitename),
  ~plot_linmod(
    out_eval_FULL$gpp$fluxnet2015$data$adf_stats$data[ which(out_eval_FULL$gpp$fluxnet2015$data$adf_stats$sitename==.) ][[1]],
    df2 = out_eval_FULL_EVI$data$adf_stats$data[ which(out_eval_FULL_EVI$data$adf_stats$sitename==.) ][[1]],
    df3 = NULL, #out_eval_Ty$data$adf_stats$data[ which(out_eval_Ty$data$adf_stats$sitename==.) ][[1]],
    xlim = c(0,4000), ylim = c(0,4000),
    sitename = .,
    fitted = NA,
    label = "greenness",
    lab_legend = c("MODIS FPAR, spl.", "MODIS EVI")
  )
)
```

 -->

## Seasonal cycle by climate zones (Fig. 4)

More insights are provided by looking at the seasonal cycle explicitly. Plots for each site are given in the Appendix. Aggregating across multiple sites doesn't make much sense. However, I aggregated across climate zones and distinguishing between respective zones on the northern and southern hemisphere.

The classification of sites into Koeppen-Geiger climate zones is based on Falge et al. 2016. [ORNL DAAC](https://doi.org/10.3334/ORNLDAAC/1530), and complemented by extracting information from a global map. A table explaining the Koeppen-Geiger codes is given below.
```{r message=FALSE, warning=FALSE, echo=FALSE}
koeppen_legend %>% knitr::kable(caption = "Koeppen-Geiger climate zones.")
```

Plot only for climate zones where data from at least five different sites are available. 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE}
## determine which zones to plot
list_rosetta <- c(
  "Aw south"  = "Tropical savannah, dry winter, SH", 
  "BSk north" = "Arid steppe, cold", 
  "Cfa north" = "Warm tem., fully humid, hot summer", 
  "Cfb north" = "Warm tem., fully humid, warm summer",
  "Cfb south" = "Warm tem., fully humid, warm summer, SH", 
  "Csa north" = "Warm tem., dry and hot summer", 
  "Csb north" = "Warm tem., dry and warm summer", 
  "Dfb north" = "Cold, fully humid, warm summer", 
  "Dfc north" = "Cold, fully humid, cold summer", 
  "ET"        = "Polar tundra")

extract_description <- function(df, use_climatezone){
  df <- df %>% filter(climatezone == use_climatezone) %>% 
    pull(Climate)
  return(df)
}

list_rosetta <- purrr::map(
  as.list(df_zones_used$climatezone),
  ~extract_description(df_zones_used, .)
)
names(list_rosetta) <- df_zones_used$climatezone


## combine data
df_meandoy_byclim <- out_eval_FULL$gpp$fluxnet2015$data$meandoydf_byclim %>% 
  mutate( mod_mean = obs_mean) %>% 
  mutate(setup = "Observed") %>% 
  bind_rows(
    out_eval_NULL$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "NULL")
  ) %>% 
  bind_rows(
    out_eval_ORG$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "ORG")
  ) %>% 
  bind_rows(
    out_eval_BRC$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "BRC")
  ) %>% 
  bind_rows(
    out_eval_FULL$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "FULL")
  ) %>% 
  filter(climatezone %in% df_zones_used$climatezone) %>% 
  # mutate(setup = factor(setup, levels = c("Observed", "FULL", "BRC", "ORG", "NULL"))) %>% 
  left_join( dplyr::select(df_zones_used, climatezone, Climate), by = "climatezone")

df_meandoy_byclim$setup <- factor(df_meandoy_byclim$setup, levels = c("Observed", "NULL", "ORG", "BRC", "FULL"))

cols <- myjcolors(4)

## plot
df_meandoy_byclim %>% 
  ggplot() +
  geom_ribbon(
    data = dplyr::filter(df_meandoy_byclim, setup=="Observed"), 
    aes(x = doy, ymin = obs_min, ymax = obs_max), fill = "black", alpha = 0.3
    ) +
  geom_line(aes(x = doy, y = mod_mean, color = setup), size = 0.4) +
  labs(y = expression( paste("Simulated GPP (g C m"^-2, " d"^-1, ")" ) ), 
       x = "DOY") +
  facet_wrap( ~climatezone ) +    # , labeller = labeller(climatezone = list_rosetta)
  theme_gray() +
  theme(legend.position = "bottom") +
  scale_color_manual(
    name="Setup: ",
    # values=c("black", "red", "royalblue", "#E69F00", "darkseagreen3")
    values=c("Observed" = "black",  "FULL" = "#DE1A1A", "BRC" = "#574AE2", "ORG" = "#29BF12", "NULL" = "#00A5CF")
    )
ggsave("fig/meandoy_byzone.pdf", width=8, height=8)
```


## Drought response (Fig. 5)

Load fLUE data to use their definition of soil moisture droughts.
```{r}
library(readr)
source("align_events.R")
source("eval_droughtresponse.R")
source("plot_dday.R")
load("data/obs_eval_NT.Rdata")

load("data/mod_BRC.Rdata")
df_dday_agg_BRC <- eval_droughtresponse( 
  mod = mod$daily, 
  obs = obs_eval_NT$ddf, 
  path_flue = "~/data/flue/flue_stocker18nphyt.csv",
  before=20, 
  after=105,
  leng_threshold = 10, 
  nbins=10, 
  do_norm=TRUE
  )

load("data/mod_FULL_FPARitp.Rdata")
df_dday_agg_FULL <- eval_droughtresponse( 
  mod = mod$daily, 
  obs = obs_eval_NT$ddf, 
  path_flue = "~/data/flue/flue_stocker18nphyt.csv",
  before=20, 
  after=105,
  leng_threshold = 10, 
  nbins=10, 
  do_norm=TRUE
  )
df_dday_agg <- df_dday_agg_BRC %>% 
  mutate(setup = "BRC") %>% 
  bind_rows(
    mutate( df_dday_agg_FULL, setup = "FULL")
    )
usecol = colorRampPalette( c("wheat3", "white") )( 5 )[2]
df_dday_agg %>% 
  ggplot() +
  # annotate("rect", xmin = 0, xmax = 105, ymin = -1.2, ymax = 2.2, alpha = .8, fill = usecol) + 
  geom_hline(yintercept = 0, color = "black", linetype = "dotted") +
  geom_vline(xintercept = 0, color = "black", linetype = "dotted") +
  geom_line(
    aes(x = dday, y = bias_gpp_median, color = setup)) +
  geom_ribbon(
    aes(x = dday, ymin = bias_gpp_q33, ymax = bias_gpp_q66, fill = setup), 
    alpha = 0.3) +
  scale_color_manual(values = c("BRC" = "black", "FULL" = "royalblue"), name = "Setup") +
  scale_fill_manual(values = c("BRC" = "black", "FULL" = "royalblue"), name = "Setup") +
  ylim(-1.2, 2.2) + xlim(-20, 105) +
  scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) +
  labs(x = "Days after drought onset", y = expression( paste( "Bias (g C m"^{-1}, " d"^{-1}, ")")) )
ggsave("fig/droughtresponse.pdf", width = 6, height = 4)
```


## Mean seasonal cycle for different greenness data (Fig. 6)

Look at seasonality for three zones with alternative greenness data.
```{r echo=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
if (!exists("out_eval_FULL")) load("data/out_eval_FULL.Rdata")
if (!exists("out_eval_FULL_FPARitp")) load("data/out_eval_FULL_FPARitp.Rdata")
if (!exists("out_eval_FULL_EVI"))    load("data/out_eval_FULL_EVI.Rdata")
  
## combine data
df_meandoy_byclim <- out_eval_FULL$gpp$fluxnet2015$gpp$fluxnet2015$data$meandoydf_byclim %>% 
  bind_rows() %>%
  mutate( mod_mean = obs_mean) %>% 
  mutate(setup = "Observed") %>% 
  bind_rows(
    out_eval_FULL$gpp$fluxnet2015$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "FULL")
  ) %>% 
  bind_rows(
    out_eval_FULL_FPARitp$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "FULL_FPARitp")
  ) %>% 
  bind_rows(
    out_eval_FULL_EVI$gpp$fluxnet2015$data$meandoydf_byclim %>% 
    bind_rows() %>% 
    mutate(setup = "FULL_EVI")
  ) %>% 
  filter(climatezone %in% c("Dfb north", "BSk north")) %>% 
  # mutate(setup = factor(setup, levels = c("Observed", "FULL", "BRC", "ORG", "NULL"))) %>% 
  left_join(select(df_zones_used, climatezone, Climate), by = "climatezone")
df_meandoy_byclim$setup <- factor(df_meandoy_byclim$setup, levels = c("FULL_EVI", "FULL_FPARitp", "Observed", "FULL"))

## new try
df_meandoy_byclim %>% 
  ggplot() +
  geom_ribbon(
    data = dplyr::filter(df_meandoy_byclim, setup=="Observed"), 
    aes(x = doy, ymin = obs_min, ymax = obs_max), fill = "black", alpha = 0.3
    ) +
  geom_line(aes(x = doy, y = mod_mean, color = setup), size = 0.4) +
  labs(y = expression( paste("Simulated GPP (g C m"^-2, " d"^-1, ")" ) ), 
       x = "DOY") +
  facet_wrap( ~climatezone, labeller = labeller(climatezone = list_rosetta) ) +
  theme_gray() +
  theme(legend.position = "bottom") +
  scale_color_manual(
    name="Setup: ", 
    values=c("Observed" = "black",  "FULL" = "red", "FULL_FPARitp" = "royalblue", "FULL_EVI" = "#E69F00")
    ) 
ggsave("fig/meandoy_byzone_greenness.pdf", width=6, height=3.5)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
source("plot_modobs_spatial_annual.R")
plot_modobs_spatial_annual( out_eval_FULL, xlim = c(0,4000), ylim = c(0,4000), makepdf = TRUE, label = "FULL" )
plot_modobs_spatial_annual( out_eval_FULL_EVI, xlim = c(0,4000), ylim = c(0,4000), makepdf = TRUE, label = "EVI" )
```

### GPP flux decomposition method (Fig. 7)

Look at seasonality for three zones with alternative greenness data.
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
if (!exists("out_eval_NTsub"))  load("data/out_eval_NTsub.Rdata")
if (!exists("out_eval_DT"))     load("data/out_eval_DT.Rdata")
if (!exists("out_eval_Ty"))     load("data/out_eval_Ty.Rdata")

## MEAN SEASONALITY
## NT
gg_NT <- out_eval_NTsub$gpp$fluxnet2015$data$meandoydf_byclim %>% 
  bind_rows() %>% 
  filter(climatezone == "Cfb north") %>% 
  ggplot() +
  geom_ribbon(aes(x = doy, ymin = obs_min, ymax = obs_max), fill = "black", alpha = 0.3) +
  geom_line(aes(x = doy, y = obs_mean), size = 0.4) +
  geom_line(aes(x = doy, y = mod_mean), size = 0.4, color = "red") +
  labs(y = expression( paste("Simulated GPP (g C m"^-2, " d"^-1, ")" ) ), 
       x = "DOY", title = "NT") +
  theme_gray() +
  theme(legend.position = "bottom") +
  scale_color_manual(
    name="Setup: ", 
    values=c("Observed" = "black",  "NT" = "red")
    ) 
gg_DT <- out_eval_DT$gpp$fluxnet2015$data$meandoydf_byclim %>% 
  bind_rows() %>% 
  filter(climatezone == "Cfb north") %>% 
  ggplot() +
  geom_ribbon(aes(x = doy, ymin = obs_min, ymax = obs_max), fill = "black", alpha = 0.3) +
  geom_line(aes(x = doy, y = obs_mean), size = 0.4) +
  geom_line(aes(x = doy, y = mod_mean), size = 0.4, color = "red") +
  labs(y = expression( paste("Simulated GPP (g C m"^-2, " d"^-1, ")" ) ), 
       x = "DOY", title = "DT") +
  theme_gray() +
  theme(legend.position = "bottom") +
  scale_color_manual(
    name="Setup: ", 
    values=c("Observed" = "black",  "DT" = "red")
    ) 
gg_Ty <- out_eval_Ty$gpp$fluxnet2015$data$meandoydf_byclim %>% 
  bind_rows() %>% 
  filter(climatezone == "Cfb north") %>% 
  ggplot() +
  geom_ribbon(aes(x = doy, ymin = obs_min, ymax = obs_max), fill = "black", alpha = 0.3) +
  geom_line(aes(x = doy, y = obs_mean), size = 0.4) +
  geom_line(aes(x = doy, y = mod_mean), size = 0.4, color = "red") +
  labs(y = expression( paste("Simulated GPP (g C m"^-2, " d"^-1, ")" ) ), 
       x = "DOY", title = "Ty") +
  theme_gray() +
  theme(legend.position = "bottom") +
  scale_color_manual(
    name="Setup: ", 
    values=c("Observed" = "black",  "Ty" = "red")
    ) 

## SCATTER PLOT
  ## get stats and plot
  modobs_xdf_NT <- analyse_modobs2(
    out_eval_NTsub$gpp$fluxnet2015$data$xdf,
    "gpp_mod",
    "gpp_obs",
    type = "heat"
    )
  modobs_xdf_DT <- analyse_modobs2(
    out_eval_DT$gpp$fluxnet2015$data$xdf,
    "gpp_mod",
    "gpp_obs",
    type = "heat"
    )  
  modobs_xdf_Ty <- analyse_modobs2(
    out_eval_Ty$gpp$fluxnet2015$data$xdf,
    "gpp_mod",
    "gpp_obs",
    type = "heat"
    )  
  
  ## print plot
  gg_modobs_NT <- modobs_xdf_NT$gg +
    labs(x = expression( paste("simulated GPP (gC m"^-2, "d"^-1, ")" ) ), 
         y = expression( paste("observed GPP (gC m"^-2, "d"^-1, ")" ) ),
         title = "NT") +
    xlim(0, 20) +
    ylim(0, 20)
  gg_modobs_DT <- modobs_xdf_DT$gg +
    labs(x = expression( paste("simulated GPP (gC m"^-2, "d"^-1, ")" ) ), 
         y = expression( paste("observed GPP (gC m"^-2, "d"^-1, ")" ) ),
         title = "DT") +
    xlim(0, 20) +
    ylim(0, 20)
  gg_modobs_Ty <- modobs_xdf_Ty$gg +
    labs(x = expression( paste("simulated GPP (gC m"^-2, "d"^-1, ")" ) ), 
         y = expression( paste("observed GPP (gC m"^-2, "d"^-1, ")" ) ),
         title = "Ty") +
    xlim(0, 20) +
    ylim(0, 20)
  
## arrange and save
cowplot::plot_grid(gg_NT, gg_DT, gg_Ty, gg_modobs_NT, gg_modobs_DT, gg_modobs_Ty, nrow = 2, labels = "auto", label_size = 12, rel_heights = c(1, 1.2))
filn <- paste0( dir_figs, "meandoy_modobs_gpp_data.pdf" )
ggsave(filn, width=10, height=7)  
```


## Daily anomalies (Fig. 11)

```{r}
ddf <- out_eval_FULL$gpp$fluxnet2015$data$idvdf %>% 
  tidyr::drop_na(gpp_obs) %>% 
  select(gpp_mod, gpp_obs) %>%
  tidyr::gather(source, anom, c(gpp_obs, gpp_mod))
xdf <- out_eval_FULL$gpp$fluxnet2015$data$ixvdf %>% 
  tidyr::drop_na(gpp_obs) %>% 
  select(gpp_mod, gpp_obs) %>%
  tidyr::gather(source, anom, c(gpp_obs, gpp_mod))
gg_ddf <- ddf %>% 
  ggplot() +
  geom_histogram(
    aes(x = anom, y = ..density.., fill = source), 
    color = "black", alpha = 0.3, binwidth = 0.5, 
    position="identity") +
  scale_fill_manual(name = "", values = c("black", "red"), labels = c("Observed", "Modelled")) +
  annotate( 
    "text", x = 5, y = 0.8, 
    label = paste("sigma[obs] == ", 
                  format( sd(out_eval_FULL$gpp$fluxnet2015$data$idvdf$gpp_obs, na.rm = TRUE), digits = 3)), 
    parse = TRUE, hjust = 0) +
  annotate( 
    "text", x = 5, y = 0.76, 
    label = paste("sigma[mod] == ", 
                  format( sd(out_eval_FULL$gpp$fluxnet2015$data$idvdf$gpp_mod, na.rm = TRUE), digits = 3)), 
    parse = TRUE, hjust = 0) +
  xlim(-10,10) + ylim(0, 0.8) +
  theme(legend.position=c(0.05, 0.95), 
        plot.title = element_text(hjust = 0)) +
  labs( y = "Density", x =  expression( paste("GPP anomaly (gC m"^-2, " d"^-1, ")" ) ),
        title = "Daily")
gg_xdf <- xdf %>% 
  ggplot() +
  geom_histogram(
    aes(x = anom, y = ..density.., fill = source), 
    color = "black", alpha = 0.3, binwidth = 0.5, 
    position="identity") +
  scale_fill_manual(name = "", values = c("black", "red"), labels = c("Observed", "Modelled"), guide=FALSE) +
  annotate( 
    "text", x = 4, y = 0.8, 
    label = paste("sigma[obs] == ", 
                  format( sd(out_eval_FULL$gpp$fluxnet2015$data$ixvdf$gpp_obs, na.rm = TRUE), digits = 3)), 
    parse = TRUE, hjust = 0) +
  annotate( 
    "text", x = 4, y = 0.76, 
    label = paste("sigma[mod] == ", 
                  format( sd(out_eval_FULL$gpp$fluxnet2015$data$ixvdf$gpp_mod, na.rm = TRUE), digits = 3)), 
    parse = TRUE, hjust = 0) +
  xlim(-10,10) + ylim(0, 0.8) +
  theme(plot.title = element_text(hjust = 0)) +
  labs( y = "Density", x =  expression( paste("GPP anomaly (gC m"^-2, " d"^-1, ")" ) ),
        title = "8-daily")
cowplot::plot_grid(gg_ddf, gg_xdf, nrow = 1, labels = "auto", label_size = 12)
ggsave("fig/hist_anomalies.pdf", width = 7, height = 4)
```


## Remaining figures

- For Fig. 8 and 9, see `eval_pmodel_global.Rmd`.
- For Fig. 10, see XXX MISSING RMD FILE ON GITHUB XXX

<!-- 
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

## Evaluation settings


### Check evaluation site selection

 
## Evaluation of different simulation suites

Parameters are calibrated for six different simulation suites and parameter values saved in CSV files. The simulation suites are FLUXNET site-scale simulations with different fAPAR input data, differrent GPP calibration target data, and different model setups. 

### NULL: Null model of constant LUE

Assume that light use efficiency (LUE) is constant and GPP is calculated as:
$$
\text{GPP} = \text{fAPAR} \times \text{PAR} \times \text{LUE}  
$$
LUE is a constant and is calibrated, given GPP data (here based on the nighttime decomposition method). fAPAR is splined MODIS FPAR MCD15A3H.

```{r, eval=TRUE, message=FALSE, warning=FALSE}
path_siteinfo <- "~/eval_pmodel/siteinfo_pet_fluxnet2015.csv"
settings_sims_NULL <- list(
  siteinfo       = path_siteinfo,
  ensemble       = TRUE,
  setup          = "site",
  name           = "fluxnet2015",
  dir_sofun      = "~/sofun/",
  path_output    = "~/sofun_outputs/output_fluxnet2015_sofun/202/",
  path_output_nc = "~/sofun_outputs/output_nc_fluxnet2015_sofun/s202/",
  path_input     = "~/sofun_inputs/input_fluxnet2015_sofun/",
  grid           = NA,
  implementation = "fortran",
  in_ppfd        = TRUE,
  in_netrad      = FALSE,
  recycle        = 1,
  spinupyears    = 10,
  calibvars      = c("gpp"),
  soilmstress    = FALSE,
  tempstress     = FALSE,
  loutdgpp       = TRUE,
  loutdwcont     = FALSE,
  loutdaet       = FALSE,
  loutdpet       = FALSE,
  loutdalpha     = FALSE,
  loutdgpp       = TRUE,
  loutdrd        = FALSE,
  loutdtransp    = FALSE,
  loutdwcont     = FALSE,
  loutdaet       = FALSE,
  loutdpet       = FALSE,
  loutdalpha     = FALSE
  )

setup_sofun <- list(
  model      = "pmodel",
  dir        = "~/sofun",
  do_compile = FALSE,
  simsuite   = FALSE
  )

settings_sims_NULL <- prepare_setup_sofun( 
  settings = settings_sims_NULL,
  setup = setup_sofun,
  write_paramfils = FALSE 
  )

mylist <- readr::read_csv("~/eval_pmodel/myselect_fluxnet2015.csv") %>% 
  dplyr::filter( use==1 ) %>% 
  dplyr::pull( Site )

settings_eval_NULL <- list(
  sitenames = settings_sims_NULL$sitenames,
  sitenames_siteplots = mylist,
  agg = 8,
  path_fluxnet2015_d = "~/data/FLUXNET-2015_Tier1/20160128/point-scale_none_1d/original/unpacked/",
  path_fluxnet2015_w = "~/data/FLUXNET-2015_Tier1/20160128/point-scale_none_7d/original/unpacked/",
  path_fluxnet2015_m = "~/data/FLUXNET-2015_Tier1/20160128/point-scale_none_1m/original/unpacked/",
  path_fluxnet2015_y = "~/data/FLUXNET-2015_Tier1/20160128/point-scale_none_1y/original/unpacked/",
  path_gepisat_d     = "~/data/gepisat/v3_fluxnet2015/daily_gpp/",
  benchmark = list( gpp = c("fluxnet2015_NT") ),
  remove_premodis = TRUE
  )

save(settings_sims_NULL, file = "./data/settings_sims_NULL.Rdata")
save(settings_eval_NULL, file = "./data/settings_eval_NULL.Rdata")

if (!exists("ddf_obs_eval_NT")){
  filn <- "~/eval_pmodel/data/ddf_obs_eval_NT_WITHFORCING.Rdata"
  if (file.exists(filn)){
    load(filn)
  } else {
    ddf_obs_eval_NT  <- get_obs_eval( 
      settings_eval = settings_eval_NULL, 
      settings_sims = settings_sims_NULL, 
      overwrite = TRUE, 
      light = FALSE 
      )
    save(ddf_obs_eval_NT, file = filn)
  }
}

mod_NULL <- ddf_obs_eval$ddf %>% 
            dplyr::select( sitename, date, gpp, ppfd_fluxnet2015, fapar ) %>% 
            mutate( apar = ppfd_fluxnet2015 * fapar ) %>% 
            mutate( gpp = ifelse( date < "2000-02-18", NA, gpp ) )
            
## to fit constant LUE, fit linear model with zero intercept and just use its coefficient (slope)
linmod <- lm( gpp ~ 0 + apar, data = mod_NULL )
save(linmod, file="data/linmod_NULL.RData")
mod_NULL <- mod_NULL %>% 
  dplyr::select( sitename, date, apar ) %>%
  mutate( gpp = coef(linmod) * apar ) %>%
  dplyr::select( -apar )

mod_NULL <- list(daily = mod_NULL)

out_eval_NULL <- eval_sofun( mod_NULL, settings_eval_NULL, settings_sims_NULL, obs_eval = ddf_obs_eval_NT, overwrite = TRUE )

row_rsqtable_NULL <- bind_cols( Setup = "NULL", getrow_statstable( out_eval_NULL, stat = "rsq" ) )
```



### ORG: Original setup

Without soil moisture stress and with constant quantum yield effiency. Run SOFUN with calibrated parameters for the simulation suite based on splined MODIS FPAR MCD15A3H fAPAR data and excluding cold (<10$^{\circ}$) and dry (relative soil moisture below XXX) days. and  `r `
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## out-of-bag calibration/evaluation
load("./data/out_oob_ORG.Rdata")

## extract metrics from individual left-out calibrations/evaluations
df_metrics_oob_ORG <- extract_metric_oob(out_oob_ORG, metric = "rsq") %>% 
  left_join(extract_metric_oob(out_oob_ORG, metric = "rmse"), by = "sitename")

# get parameters from individual left-out calibrations
df_params_oob_ORG <- extract_params_oob(param = "kphio", path = "~/eval_pmodel/calib_results/org/", sitenames = df_metrics_oob$sitename)
  
# get calibrated parameters from single-site calibration
df_params_single_ORG <- read_csv("./calib_results/org/params_opt_ORG.csv")

# get evaluation results from single-site calibration ('out_eval_ORG')
load("./calib_results/out_eval_ORG.Rdata")

df_params_oob_ORG %>% 
  ggplot() +
  geom_histogram(aes(x=kphio, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.0001, 
    position="identity") +
  geom_vline(xintercept = df_params_single_ORG$kphio, col = "red") +
  theme_classic() +
  labs(x = latex2exp::TeX("$\\widehat{\\varphi_0} \\;(mol\\; mol^{-1})$"), y = "Count", title = "ORG") +   # bquote(varphi[0])
  xlim(x = c(0.048, 0.052))

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rsq, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.05, 
    position="identity") +
  geom_vline(xintercept = out_eval_ORG$gpp$fluxnet2015$metrics$xdaily_pooled$rsq, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rsq), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = bquote(italic(R)^2), y = "Count")

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rmse, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.5, 
    position="identity") +
  geom_vline(xintercept = out_eval_ORG$gpp$fluxnet2015$metrics$xdaily_pooled$rmse, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rmse), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = expression( paste("RMSE (g C m"^-2, " d"^-1, ")" ) ), y = "Count")

row_rsqtable_ORG <- bind_cols( Setup = "ORG", getrow_statstable( out_eval_ORG, stat = "rsq" ) )
```

### BRC: Temperature-dependent quantum yield efficiency

```{r, eval=TRUE, message=FALSE, warning=FALSE}
## out-of-bag calibration/evaluation
if (!exists("out_oob_BRC")){ 
  load("./data/out_oob_BRC.Rdata") 
}

## extract metrics from individual left-out calibrations/evaluations
df_metrics_oob_ORG <- extract_metric_oob(out_oob_BRC, metric = "rsq") %>% 
  left_join(extract_metric_oob(out_oob_BRC, metric = "rmse"), by = "sitename")

# get parameters from individual left-out calibrations
df_params_oob_BRC <- extract_params_oob(param = "kphio", path = "~/eval_pmodel/calib_results/BRC/", sitenames = df_metrics_oob$sitename)
  
# get calibrated parameters from single-site calibration
df_params_single_BRC <- read_csv("./calib_results/BRC/params_opt_BRC.csv")

# get evaluation results from single-site calibration ('out_eval_BRC')
if (!exists("out_eval_BRC")){
  load("./calib_results/out_eval_BRC.Rdata") 
}

df_params_oob_BRC %>% 
  ggplot() +
  geom_histogram(aes(x=kphio, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.0001, 
    position="identity") +
  geom_vline(xintercept = df_params_single_BRC$kphio, col = "red") +
  theme_classic() +
  labs(x = latex2exp::TeX("$\\widehat{c_L} \\;(mol\\; mol^{-1})$"), y = "Count") +  # bquote(varphi[0])
  xlim(x = c(0.08, 0.083))

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rsq, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.05, 
    position="identity") +
  geom_vline(xintercept = out_eval_BRC$gpp$fluxnet2015$metrics$xdaily_pooled$rsq, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rsq), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = bquote(italic(R)^2), y = "Count")

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rmse, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.5, 
    position="identity") +
  geom_vline(xintercept = out_eval_BRC$gpp$fluxnet2015$metrics$xdaily_pooled$rmse, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rmse), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = expression( paste("RMSE (g C m"^-2, " d"^-1, ")" ) ), y = "Count")

row_rsqtable_BRC <- bind_cols( Setup = "BRC", getrow_statstable( out_eval_BRC, stat = "rsq" ) )

```


### FULL

```{r, eval=TRUE, message=FALSE, warning=FALSE}
## out-of-bag calibration/evaluation
if (!exists("out_oob_FULL")){ 
  load("./data/out_oob_FULL.Rdata") 
}

## extract metrics from individual left-out calibrations/evaluations
df_metrics_oob_ORG <- extract_metric_oob(out_oob_FULL, metric = "rsq") %>% 
  left_join(extract_metric_oob(out_oob_FULL, metric = "rmse"), by = "sitename")

# get parameters from individual left-out calibrations
df_params_oob_FULL <- extract_params_oob(param = "kphio", path = "~/eval_pmodel/calib_results/FULL/", sitenames = df_metrics_oob$sitename)
  
# get calibrated parameters from single-site calibration
df_params_single_FULL <- read_csv("./calib_results/FULL/params_opt_FULL.csv")

# get evaluation results from single-site calibration ('out_eval_FULL')
if (!exists("out_eval_FULL")){
  load("./calib_results/out_eval_FULL.Rdata") 
}

df_params_oob_FULL %>% 
  ggplot() +
  geom_histogram(aes(x=kphio, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.0001, 
    position="identity") +
  geom_vline(xintercept = df_params_single_FULL$kphio, col = "red") +
  theme_classic() +
  labs(x = latex2exp::TeX("$\\widehat{c_L} \\;(mol\\; mol^{-1})$"), y = "Count") +  # bquote(varphi[0])
  xlim(x = c(0.08, 0.083))

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rsq, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.05, 
    position="identity") +
  geom_vline(xintercept = out_eval_FULL$gpp$fluxnet2015$metrics$xdaily_pooled$rsq, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rsq), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = bquote(italic(R)^2), y = "Count")

df_metrics_oob %>% 
  ggplot() +
  geom_histogram(aes(x = rmse, y = ..count..),
    color = "black", alpha = 0.3, binwidth = 0.5, 
    position="identity") +
  geom_vline(xintercept = out_eval_FULL$gpp$fluxnet2015$metrics$xdaily_pooled$rmse, col = "red") +
  geom_vline(xintercept = mean(df_metrics_oob$rmse), col = "red", linetype = "dashed") + 
  theme_classic() +
  labs(x = expression( paste("RMSE (g C m"^-2, " d"^-1, ")" ) ), y = "Count")

row_rsqtable_FULL <- bind_cols( Setup = "FULL", getrow_statstable( out_eval_FULL, stat = "rsq" ) )
```


### Summary

Get tables summarising all setups.
```{r}
bind_rows(row_rsqtable_BRC, row_rsqtable_ORG, row_rsqtable_NULL) %>% 
  dplyr::select(Setup, xdaily, spatial, annual, seasonal, daily_var, annual_var)

df_params_single_ORG %>%
  bind_rows(df_params_single_BRC)
```

### FULL: Full simulations, including soil moisture and temperature stress

Run SOFUN with calibrated parameters for the simulation suite based on splined MODIS FPAR MCD15A3H fAPAR data and excluding cold (<10$^{\circ}$) and dry (relative soil moisture below XXX) days. and  `r `
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s203/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN - THE SAME AS ABOVE
settings_input$fapar = "MODIS_FPAR_MCD15A3H"
settings_input$splined_fapar = TRUE
## run the model with these parameters and read output into mod_FULL
if (!file.exists("data/mod_FULL.Rdata")){
  settings_sims <- prepare_setup_sofun(
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = TRUE 
    )
  # Prepare and save input data for later use - THE SAME AS ABOVE
  inputdata_FPARspl <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_csv_fapar = FALSE, 
    overwrite_fapar = FALSE, 
    verbose = TRUE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  mod_FULL <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL, file = "data/mod_FULL.Rdata" )
} else {
  load("data/mod_FULL.Rdata")
}
## Define other setup-specific evaluation settings - THE SAME AS ABOVE
settings_eval$benchmark <- list( gpp = c("fluxnet2015_NT") )
# get observational data separately and save since it's the same for multiple evaluations - THE SAME AS ABOVE
if (!file.exists("data/obs_eval_NT.Rdata")){
  obs_eval_NT <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  save( obs_eval_NT, file = "data/obs_eval_NT.Rdata")
} else {
  load("data/obs_eval_NT.Rdata")
}
## evaluate FULL simulations
if (!file.exists("data/out_eval_FULL.Rdata")){
  out_eval_FULL <- eval_sofun( mod_FULL, settings_eval, settings_sims, obs_eval = obs_eval_NT, overwrite = TRUE )
  save( out_eval_FULL, file = "data/out_eval_FULL.Rdata" )
} else {
  if (!exists("out_eval_FULL")) load("data/out_eval_FULL.Rdata")
}
row_rsqtable_FULL <- bind_cols( Setup = "FULL", getrow_statstable( out_eval_FULL, stat = "rsq" ) )
rm("mod_FULL")
```


### FULL_FPARitp: Sensitivity to greenness data with interpolated FPAR data

Run SOFUN with calibrated parameters for the simulation suite based on splined MODIS FPAR MCD15A3H fAPAR data and excluding cold (<10$^{\circ}$) and dry (relative soil moisture below XXX) days. and  `r `
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s204/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN
settings_input$fapar = "MODIS_FPAR_MCD15A3H"
settings_input$splined_fapar = FALSE
## run the model with these parameters and read output into mod_FULL_FPARitp
if (!file.exists("data/mod_FULL_FPARitp.Rdata")){
  settings_sims <- prepare_setup_sofun( 
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = TRUE 
    )
  ## Prepare and save input data for later use
  inputdata_FPATitpl <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_csv_fapar = TRUE, 
    overwrite_fapar = TRUE, 
    verbose = TRUE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL_FPARitp.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  mod_FULL_FPARitp <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL_FPARitp, file = "data/mod_FULL_FPARitp.Rdata" )
} else {
  load("data/mod_FULL_FPARitp.Rdata")
}
## Define other setup-specific evaluation settings
settings_eval$benchmark <- list( gpp = c("fluxnet2015_NT") )
## get observational data separately and save since it's the same for multiple evaluations
if (!file.exists("data/obs_eval_NT.Rdata")){
  obs_eval_NT <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  save( obs_eval_NT, file = "data/obs_eval_NT.Rdata")
} else {
  load("data/obs_eval_NT.Rdata")
}
## evaluate FULL_FPARitp simulations
if (!file.exists("data/out_eval_FULL_FPARitp.Rdata")){
  out_eval_FULL_FPARitp <- eval_sofun( mod_FULL_FPARitp, settings_eval, settings_sims, obs_eval = obs_eval_NT, overwrite = TRUE )
  save( out_eval_FULL_FPARitp, file = "data/out_eval_FULL_FPARitp.Rdata" )
} else {
  if (!exists("out_eval_FULL_FPARitp")) load("data/out_eval_FULL_FPARitp.Rdata")
}
row_rsqtable_FULL_FPARitp <- bind_cols( Setup = "FULL_FPARitp", getrow_statstable( out_eval_FULL_FPARitp, stat = "rsq" ) )
# rm("out_eval_FULL_FPARitp")
rm("mod_FULL_FPARitp")
```


### FULL_EVI: Sensitivity to greenness data with interpolated EVI data

Run SOFUN with calibrated parameters for the simulation suite based on splined MODIS FPAR MCD15A3H fAPAR data and excluding cold (<10$^{\circ}$) and dry (relative soil moisture below XXX) days. and  `r `
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s205/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN
settings_input$fapar = "MODIS_EVI_MOD13Q1"
settings_input$splined_fapar = FALSE
## run the model with these parameters and read output into mod_FULL_EVI
if (!file.exists("data/mod_FULL_EVI.Rdata")){
  settings_sims <- prepare_setup_sofun( 
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = TRUE 
    )
  ## Prepare and save input data for later use
  inputdata_EVI <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_fapar = TRUE, 
    overwrite_csv_fapar = TRUE, 
    verbose = FALSE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL_EVI.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  settings_sims$loutdrd     = FALSE
  settings_sims$loutdtransp = FALSE
  mod_FULL_EVI <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL_EVI, file = "data/mod_FULL_EVI.Rdata" )
} else {
  load("data/mod_FULL_EVI.Rdata")
}
## Define other setup-specific evaluation settings
settings_eval$benchmark <- list( gpp = c("fluxnet2015_NT") )
## get observational data separately and save since it's the same for multiple evaluations
if (!file.exists("data/obs_eval_NT.Rdata")){
  obs_eval_NT <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  save( obs_eval_NT, file = "data/obs_eval_NT.Rdata")
} else {
  load("data/obs_eval_NT.Rdata")
}
## evaluate FULL_EVI simulations
if (!file.exists("data/out_eval_FULL_EVI.Rdata")){
  out_eval_FULL_EVI <- eval_sofun( mod_FULL_EVI, settings_eval, settings_sims, obs_eval = obs_eval_NT, overwrite = TRUE )
  save( out_eval_FULL_EVI, file = "data/out_eval_FULL_EVI.Rdata" )
} else {
  if (!exists("out_eval_FULL_EVI")) load("data/out_eval_FULL_EVI.Rdata")
}
row_rsqtable_FULL_EVI <- bind_cols( Setup = "FULL_EVI", getrow_statstable( out_eval_FULL_EVI, stat = "rsq" ) )
# rm("out_eval_FULL_EVI")
rm("mod_FULL_EVI")
```


### FULL_DT: Sensitivity to GPP data with DT

Calibrating and evaluating SOFUN against GPP data based on the daytime decomposition method.
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s206/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN
settings_input$fapar = "MODIS_FPAR_MCD15A3H"
settings_input$splined_fapar = TRUE
## run the model with these parameters and read output into mod_FULL_EVI
if (!file.exists("data/mod_FULL_DT.Rdata")){
  settings_sims <- prepare_setup_sofun( 
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = TRUE
    )
  ## Prepare and save input data for later use
  inputdata_FPARspl <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_csv_fapar = TRUE, 
    overwrite_fapar = TRUE, 
    verbose = TRUE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL_DT.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  settings_sims$loutdrd     = FALSE
  settings_sims$loutdtransp = FALSE
  mod_FULL_DT <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL_DT, file = "data/mod_FULL_DT.Rdata" )
} else {
  load("data/mod_FULL_DT.Rdata")
}
## Define other setup-specific evaluation settings
settings_eval$benchmark <- list( gpp = c("fluxnet2015_DT") )
settings_eval$filter_days = c("fluxnet2015_Ty", "fluxnet2015_DT", "fluxnet2015_NT")
## get observational data separately and save since it's the same for multiple evaluations
if (!file.exists("data/obs_eval_DT.Rdata")){
  obs_eval_DT <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  # obs_eval_DT$ddf <- obs_eval_DT$ddf %>% filter_days( settings_eval$filter_days, settings_eval$path_gepisat )
  print(paste0("Total number of evaluation data points: ", sum(!is.na(obs_eval_DT$ddf$gpp_obs))))
  save( obs_eval_DT, file = "data/obs_eval_DT.Rdata")
} else {
  load("data/obs_eval_DT.Rdata")
}
```

### FULL_NTsub: Sensitivity to GPP data

```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s207/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN
settings_input$fapar = "MODIS_FPAR_MCD15A3H"
settings_input$splined_fapar = TRUE
## run the model with these parameters and read output into mod_FULL_EVI
if (!file.exists("data/mod_FULL_NTsub.Rdata")){
  settings_sims <- prepare_setup_sofun( 
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = TRUE
    )
  ## Prepare and save input data for later use
  inputdata_FPARspl <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_csv_fapar = TRUE, 
    overwrite_fapar = TRUE, 
    verbose = TRUE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL_NTsub.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  settings_sims$loutdrd     = FALSE
  settings_sims$loutdtransp = FALSE
  mod_FULL_NTsub <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL_NTsub, file = "data/mod_FULL_NTsub.Rdata" )
} else {
  load("data/mod_FULL_NTsub.Rdata")
}
## Define other setup-specific evaluation settings
settings_eval$benchmark <- list( gpp = c("fluxnet2015_NT") )
settings_eval$filter_days = c("fluxnet2015_Ty", "fluxnet2015_DT", "fluxnet2015_NT")
## get observational data separately and save since it's the same for multiple evaluations
if (!file.exists("data/obs_eval_NTsub.Rdata")){
  obs_eval_NTsub <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  # obs_eval_NTsub$ddf <- obs_eval_NTsub$ddf %>% filter_days( settings_eval$filter_days, settings_eval$path_gepisat )
  print(paste0("Total number of evaluation data points: ", sum(!is.na(obs_eval_NTsub$ddf$gpp_obs))))
  save( obs_eval_NTsub, file = "data/obs_eval_NTsub.Rdata")
} else {
  load("data/obs_eval_NTsub.Rdata")
}
```

### FULL_Ty: Sensitivity to GPP data with Ty

Calibrating and evaluating SOFUN against GPP data based on the alternative flux decomposition method by Tyler's method (GePiSaT data).
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Define new output directory and specific simulation parameters and re-run the setup step
settings_sims$path_output_nc  = "/alphadata01/bstocker/sofun/output_nc_fluxnet2015_sofun/s208/"
settings_sims$soilmstress = TRUE
settings_sims$tempstress  = TRUE
## Define fAPAR input data and re-write input files for SOFUN
settings_input$fapar = "MODIS_FPAR_MCD15A3H"
settings_input$splined_fapar = TRUE
## run the model with these parameters and read output into mod_FULL_Ty
if (!file.exists("data/mod_FULL_Ty.Rdata")){
  settings_sims <- prepare_setup_sofun( 
    settings = settings_sims,
    setup = setup_sofun,
    write_paramfils = FALSE
    )
  ## Prepare and save input data for later use
  inputdata_FPARspl <- prepare_input_sofun( 
    settings_input = settings_input, 
    settings_sims = settings_sims, 
    return_data = FALSE, 
    overwrite_csv_fapar = FALSE, 
    overwrite_fapar = FALSE, 
    verbose = TRUE
    )
  ## update files containing parameter values read by model
  params_opt <- readr::read_csv( "calib_results/params_opt_FULL_Ty.csv" )
  nothing <- update_params( params_opt, settings_sims$dir_sofun )
  settings_sims$loutdrd     = FALSE
  settings_sims$loutdtransp = FALSE
  mod_FULL_Ty <- runread_sofun( 
    settings = settings_sims, 
    setup = setup_sofun 
    )
  save( mod_FULL_Ty, file = "data/mod_FULL_Ty.Rdata" )
} else {
  load("data/mod_FULL_Ty.Rdata")
}
## Define other setup-specific evaluation settings
settings_eval$benchmark <- list( gpp = c("fluxnet2015_Ty") )
settings_eval$filter_days = c("fluxnet2015_Ty", "fluxnet2015_DT", "fluxnet2015_NT")
## get observational data separately and save since it's the same for multiple evaluations
if (!file.exists("data/obs_eval_Ty.RdataXXX")){
  obs_eval_Ty <- get_obs_eval( settings_eval = settings_eval, settings_sims = settings_sims, overwrite = TRUE )
  # obs_eval_Ty$ddf <- obs_eval_Ty$ddf %>% filter_days( settings_eval$filter_days, settings_eval$path_gepisat )
  print(paste0("Total number of evaluation data points: ", sum(!is.na(obs_eval_Ty$ddf$gpp_obs))))
  save( obs_eval_Ty, file = "data/obs_eval_Ty.Rdata")
} else {
  load("data/obs_eval_Ty.Rdata")
}
```

Evaluate in two steps, after making sure all data points are available in all setups.
```{r, eval=TRUE, message=FALSE, warning=FALSE}
## Make sure data is available in all three
# daily
merged <- select(    obs_eval_DT$ddf,    sitename, date, gpp_DT = gpp_obs ) %>% 
  left_join( select( obs_eval_NTsub$ddf, sitename, date, gpp_NT = gpp_obs ), by = c("sitename", "date") ) %>% 
  left_join( select( obs_eval_Ty$ddf,    sitename, date, gpp_Ty = gpp_obs ), by = c("sitename", "date") ) %>% 
  mutate( use = ifelse( !is.na(gpp_DT) & !is.na(gpp_NT) & !is.na(gpp_Ty), TRUE, FALSE ) ) %>% 
  mutate( gpp_DT = ifelse(use, gpp_DT, NA), gpp_NT = ifelse(use, gpp_NT, NA), gpp_Ty = ifelse(use, gpp_Ty, NA) )
sum(!is.na(merged$gpp_DT))
sum(!is.na(merged$gpp_NT))
sum(!is.na(merged$gpp_Ty))
obs_eval_DT$ddf$gpp_obs    <- merged$gpp_DT
obs_eval_NTsub$ddf$gpp_obs <- merged$gpp_NT
obs_eval_Ty$ddf$gpp_obs    <- merged$gpp_Ty
# x-daily
merged <- select(    obs_eval_DT$xdf,    sitename, inbin, gpp_DT = gpp_obs ) %>% 
  left_join( select( obs_eval_NTsub$xdf, sitename, inbin, gpp_NT = gpp_obs ), by = c("sitename", "inbin") ) %>% 
  left_join( select( obs_eval_Ty$xdf,    sitename, inbin, gpp_Ty = gpp_obs ), by = c("sitename", "inbin") ) %>% 
  mutate( use = ifelse( !is.na(gpp_DT) & !is.na(gpp_NT) & !is.na(gpp_Ty), TRUE, FALSE ) ) %>% 
  mutate( gpp_DT = ifelse(use, gpp_DT, NA), gpp_NT = ifelse(use, gpp_NT, NA), gpp_Ty = ifelse(use, gpp_Ty, NA) )
sum(!is.na(merged$gpp_DT))
sum(!is.na(merged$gpp_NT))
sum(!is.na(merged$gpp_Ty))
obs_eval_DT$xdf$gpp_obs    <- merged$gpp_DT
obs_eval_NTsub$xdf$gpp_obs <- merged$gpp_NT
obs_eval_Ty$xdf$gpp_obs    <- merged$gpp_Ty
## evaluate FULL_DT simulations
if (!file.exists("data/out_eval_DT.RdataXXX")){
  out_eval_DT <- eval_sofun( mod_FULL_DT, settings_eval, settings_sims, obs_eval = obs_eval_DT, overwrite = TRUE )
  save( out_eval_DT, file = "data/out_eval_DT.Rdata" )
} else {
  if (!exists("out_eval_DT")) load("data/out_eval_DT.Rdata")
}
row_rsqtable_FULL_DT <- bind_cols( Setup = "FULL_DT", getrow_statstable( out_eval_DT, stat = "rsq" ) )
rm("mod_FULL_DT")
## evaluate FULL_NTsub simulations
if (!file.exists("data/out_eval_NTsub.RdataXXX")){
  out_eval_NTsub <- eval_sofun( mod_FULL_NTsub, settings_eval, settings_sims, obs_eval = obs_eval_NTsub, overwrite = TRUE )
  save( out_eval_NTsub, file = "data/out_eval_NTsub.Rdata" )
} else {
  if (!exists("out_eval_NTsub")) load("data/out_eval_NTsub.Rdata")
}
row_rsqtable_FULL_NTsub <- bind_cols( Setup = "FULL_NTsub", getrow_statstable( out_eval_NTsub, stat = "rsq" ) )
rm("mod_FULL_NTsub")
## evaluate FULL_Ty simulations
if (!file.exists("data/out_eval_Ty.RdataXXX")){
  out_eval_Ty <- eval_sofun( mod_FULL_Ty, settings_eval, settings_sims, obs_eval = obs_eval_Ty, overwrite = TRUE )
  save( out_eval_Ty, file = "data/out_eval_Ty.Rdata" )
} else {
  if (!exists("out_eval_Ty")) load("data/out_eval_Ty.Rdata")
}
row_rsqtable_FULL_Ty <- bind_cols( Setup = "FULL_Ty", getrow_statstable( out_eval_Ty, stat = "rsq" ) )
rm("mod_FULL_Ty")
```


## Sites selection

Sites used for the model evaluation are shown on the map below. An overview table is in the Appendix (last section of this document).

```{r siteoverview_fig, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
require(ncdf4, quietly = TRUE)
ncfiln <- "../data/greve/ep_over_p_cru_ncep.nc"
if (!file.exists(ncfiln)) {
  epop <- array( 1, dim=c(720,360) )
} else {
  nc <- nc_open( ncfiln )
  epop <- ncvar_get( nc, varid="EP_OVER_P_CRU_NCEP" )
}
source("plot_map_siteoverview.R")
sites_used_ddf <- out_eval_FULL$gpp$fluxnet2015$data$ddf$sitename %>% unique()
identical( settings_eval$sitenames, sites_used_ddf )
siteinfo <- dplyr::filter( metainfo_Tier1_sites_kgclimate_fluxnet2015, sitename %in% sites_used_ddf )
plot_map_siteoverview( siteinfo, 1/epop, plotfiln="./fig/map_sites.pdf" ) # , 
cap_siteoverview_fig <- fig_nums( "siteoverview_fig", caption=" Geographical distribution of sites selected for the bias evaluation. Sites listed in Table S1 as group 1 are in green, sites of group 2 are in black. The color of land area represents aridity, quantified as the ratio of potential evapotranspiration over precipitation from xxx" )
```

`r fig_nums("siteoverview_fig")`

## Data processing

Daily data are used from the FLUXNET 2015 Tier 1 dataset, downloaded on 13. November, 2016. We use GPP as the mean of values based on the Nighttime Partitioning and the Daytime Partitioning method, both based on the Variable U-Star Threshold method (variables in the FLUXNET 2015 dataset named `GPP_NT_VUT_REF` and `GPP_DT_VUT_REF`). In the FLUXNET 2015 dataset, daily values are sums over half-hourly data. We use only daily values where less than 50% of respective half-hourly data is gap-filled. We further removed data points where the daytime and nighttime methods (`GPP_DT_VUT_REF` and `GPP_NT_VUT_REF`, resp.) are inconsistent. I.e., the upper and lower 2.5% quantile of the difference between each method's GPP quantification. Finally, we removed all negative daily GPP values.

## P-model parameter calibration

The P-model relies on a minimum set of free parameters. Most parameters are given by known physical laws with accurately defined parameters (e.g., viscosity of water) or well-established physiological relationships with independently constrained parameters (e.g., enzyme kinetics of C3 photosynthesis). Two key free parameters are:

- the ratio of costs for maintaining transpiration versus carboxylation $\beta$.
- the quantum yield efficiency $\varphi_0$.

We applied a value of 146.0 for $\beta$ based on independent constraints from $\delta^{13}$C measurements on leaves (Prentice et al., 2014; Wang Han et al., 2017).

$\varphi_0$ determines the fraction of absorbed light that can be used by the photosynthetic aparatus for assimilating CO$_2$. Within the P-model, this parameter acts as a linear scalar between absorbed light and GPP and therefore implies a strong sensitivity of simulated GPP to its valule. Considerable uncertainty resides in the quantification of fAPAR and some inconsistency in terms of its definition. Hence, we consider $\varphi_0$ as a free parameter that we calibrate, given the fAPAR data product used. Here, we use the MODIS FPAR MCD15A3H data product at 1 km/8 day resolution and extract values for a single pixel surrounding the flux tower location. Calibration was done ...
**OPEN POINT:**
I did a such a calibration and got $\varphi_0 = 0.0579$, as described [here](http://rpubs.com/stineb/calib_pmodel). I filtered out data points taken at low temperatures ($<5^{\circ}C$) and at low soil moisture ($<0.4$ relative soil water content). The calibration target was `GPP_NT_VUT_REF`. Now, I've implemented a more flexible and capable calibration function for SOFUN, allowing for multiple parameters to be calibrated simultaneously and accounting for uncertainty in the data. This makes use of different parameter search algorithms implemented in R.
- How to use uncertainty data from FLUXNET 2015? Just use one the nighttime partitioning and use `GPP_NT_VUT_MEAN` and `GPP_NT_VUT_SE`? Or how to account for uncertainty related to the difference between the nighttime and daytime partitioning approach? Thus: how to additionally use `GPP_DT_VUT_MEAN` and `GPP_DT_VUT_SE`?
## Metrics
Several performance metrics are calculated for different features of GPP variability. The performance metrics are:
- R$^2$
- RMSE
- slope (of regression observed over modelled)
- bias
The features of variability in GPP, for which model-observation agreement is calculated, are:
- mean annual values (giving "spatial" correlation)
- annual anomalies from mean across years
- daily values, absolute
- mean across X-day periods, absolute
- mean seasonal cycle (mean by day of year)
- daily anomalies from mean seasonal cycle


## Results of evaluation


### Save flat tables

Save flat tables of daily data as CSV files.
```{r}
write_csv(dplyr::select(out_eval_ORG$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_ORG.csv")
write_csv(dplyr::select(out_eval_BRC$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_BRC.csv")
write_csv(dplyr::select(out_eval_FULL$gpp$fluxnet2015$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL.csv")
write_csv(dplyr::select(out_eval_NULL$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_NULL.csv")
write_csv(dplyr::select(out_eval_NULLpft$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_NULLpft.csv")
write_csv(dplyr::select(out_eval_FULL_EVI$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL_EVI.csv")
write_csv(dplyr::select(out_eval_FULL_FPARitp$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL_FPARitp.csv")
write_csv(dplyr::select(out_eval_DT$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL_DT.csv")
write_csv(dplyr::select(out_eval_NTsub$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL_NTsub.csv")
write_csv(dplyr::select(out_eval_Ty$data$ddf, sitename, date, gpp_mod), path = "data_public/ddf_FULL_Ty.csv")
```


### Variability versus aggregation
```{r}
source("eval_ixv_sofun.R")
load("data/mod_FULL.Rdata")
var_vs_agg <- purrr::map( as.list(c(2,5,10,20,30)), ~eval_ixv_sofun( ., mod_FULL, settings_eval, settings_sims, obs_eval_NT$ddf ) )
var_vs_agg[[1]]$stats_bysite$slope %>% density( na.rm=T ) %>% plot()
purrr::map(as.list(2:5), ~lines( density( var_vs_agg[[.]]$stats_bysite$slope, na.rm=TRUE ) ) )
```






Insights from seasonality analysis by climate zones (results see below, red is the model, black the observations, discussing only climate zones with data from more than three sites):

- Big problems simulating GPP in the Tropics (Am, Equatorial monsoon): substantial underestimation during most of the year except a short period (Is that the dry period?). Could be related to fAPAR data contaminated by clouds except during the dry period? Unfortunately, only two sites are available in this climate zone.
- Insufficient GPP decline during dry periods in tropical and hot climates (Aw: Equatorial savannah with dry winter, and BSh: Arid Steppe hot). This is not a surprise. The empirical soil moisture correction is **not** applied here.
- Overestimation of GPP in arid steppes (BSk: Arid Steppe cold). Quite robust, seen at 7 sites in total. Probably, model improved by soil moisture correction.
- In temperate and boreal regions, early-season GPP is consistently overestimated, and late-season in most cases (Cfa: Warm temperate fully humid with hot summer, Cfb: Warm temperate fully humid with warm summer, Dfb: Snow fully humid warm summer, Dfc: Snow fully humid cool summer). It looks like at cold air (or soil?) temperatures, GPP tends to be overestimated.
- There is a general overestimation of GPP at sites in Cwcb (Warm temperate with dry winter and warm summer).

In brief, there is room for improvement by reducing GPP at low temperatures (sort of found before, but we never dealt with a temperature ramp, and why should we?) and low soil moisture (of course). fAPAR data in the tropics needs to be examined, otherwise, it looks like we have a problem with the Aw sites.

### Seasonal cycle by sites

```{r echo=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
source("plot_by_doy_allsites.R")
plot_by_doy_allsites( 
  out_eval_FULL, out_eval_BRC, out_eval_ORG, out_eval_NULL, 
  makepdf=TRUE, label="",
  lab1="FULL", lab2="BRC", lab3="ORG", lab4="NULL"
  )
```





### Functional relationships

Functional relationships seen in the data can be extracted using Artificial Neural Networks (ANN). This is done here. First, a model is fitted to observed GPP with temperature, PPFD, VPD, fAPAR, and soil moisture as predictors. Then, functional relationships are evaluated by using the trained ANN to predict values for a synthetic datasets. The synthetic dataset is generated for each predictor value. E.g. for temperature, a sample of 50 data points is drawn from the empirical distribution of VPD, fAPAR, PPFD, and soil moisture, respectively, and 50 levels of temperature (evenly from 0-40 $^{\circ}$C) Then, the dataset is created by all combinations of these variables. Finally, functional relationship between temperature and GPP are assessed by taking the mean across all variable combination for each level of temperature separately. This approach implies that for the evaluation, correlations between predictor variables in the observational dataset are ignored.

In order to improve comparability, ANNs are trained at (P-) modelled and observed GPP, and functional relationships thus derived for observed and modelled. This improves comparability and is preferred here over evaluating the model directly. As always, observations are in black and modelled in red.

```{r functionalrel, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
if (!exists("obs_eval_NTsub")) load("data/obs_eval_NTsub.Rdata")
if (!exists("obs_eval_DT")) load("data/obs_eval_DT.Rdata")
if (!exists("obs_eval_Ty")) load("data/obs_eval_Ty.Rdata")
source("eval_functionalrel.R")
source("plot_functionalrel.R")
predictors <- c("temp", "vpd", "soilm", "ppfd", "fapar")
## Calulate LUE, rename, and and aggregate data to multi-day periods
df_NT <- out_eval_NTsub$data$ddf %>%
            prepare_data_functionalrel( predictors, 
              ndays_agg = 10, 
              dovars = c(
                "gpp_obs", 
                predictors, 
                "gpp_mod"), 
              year_start = 2000, 
              year_end = 2018
              )
df_DT <- out_eval_DT$data$ddf %>%
            prepare_data_functionalrel( predictors, 
              ndays_agg = 10, 
              dovars = c(
                "gpp_obs", 
                predictors, 
                "gpp_mod"), 
              year_start = 2000, 
              year_end = 2018 
              )
df_Ty <- out_eval_Ty$data$ddf %>%
            prepare_data_functionalrel( predictors, 
              ndays_agg = 10, 
              dovars = c(
                "gpp_obs", 
                predictors, 
                "gpp_mod"), 
              year_start = 2000, 
              year_end = 2018
              )
## Apply the P-model over evaluation data and get GAM response from this noisy data
# params_opt <- readr::read_csv( "calib_results/params_opt_BRC.csv" )
# df_NT <- df_NT %>% apply_pmodel( returnvar="lue", kphio=params_opt$kphio ) %>% rename( lue_mod=varnam_pmodel ) %>% select(-out_pmodel)
## Get functional relationships of 'gpp_obs' and 'lue_mod' using GAMs
dflist_eval_gpp_obs_NT <- eval_functionalrel( 
  df_NT, 
  nam_target="gpp_obs", 
  predictors=predictors,
  nsample_target=100, nsample_predictors=300,
  overwrite = TRUE
  )
dflist_eval_gpp_obs_DT <- eval_functionalrel( 
  df_DT, 
  nam_target="gpp_obs", 
  predictors=predictors,
  nsample_target=100, nsample_predictors=300,
  overwrite = TRUE
  )
dflist_eval_gpp_obs_Ty <- eval_functionalrel( 
  df_Ty, 
  nam_target="gpp_obs", 
  predictors=predictors,
  nsample_target=100, nsample_predictors=300,
  overwrite = TRUE
  )
dflist_eval_gpp_mod <- eval_functionalrel( 
  df_NT, 
  nam_target="gpp_mod", 
  predictors=predictors,
  nsample_target=100, nsample_predictors=300,
  overwrite = TRUE
  )
# ## Get functional relationships of P-model directly (apply P-model on the same type of evaluation data used to evaluate the GAMs)
# ## get calibrated parameters
# dflist_eval_pmodel <- purrr::map( as.list(predictors), ~get_eval_data(., df_NT, predictors, nsample = 12 ) ) %>%
#                       purrr::map( ~apply_pmodel(., varnam_pmodel="lue", kphio=params_opt$kphio ) ) %>%
#                       setNames(predictors)
# dflist_eval_pmodel_stats <- purrr::map( as.list(predictors), ~get_quantiles( dflist_eval_pmodel[[.]], ., "varnam_pmodel")) %>%
#   setNames(predictors)
save(dflist_eval_gpp_obs_NT, file = "data/dflist_eval_gpp_obs_NT.Rdata")
save(dflist_eval_gpp_obs_DT, file = "data/dflist_eval_gpp_obs_DT.Rdata")
save(dflist_eval_gpp_obs_Ty, file = "data/dflist_eval_gpp_obs_Ty.Rdata")
save(dflist_eval_gpp_mod, file = "data/dflist_eval_gpp_mod.Rdata")
# save(dflist_eval_pmodel, file = "data/dflist_eval_pmodel.Rdata")
# save(dflist_eval_pmodel_stats, file = "data/dflist_eval_pmodel_stats.Rdata")
## temperature
plot_functionalrel( 
  df  = dflist_eval_gpp_obs_NT[["temp"]], 
  df2 = dflist_eval_gpp_obs_DT[["temp"]], 
  df3 = dflist_eval_gpp_obs_Ty[["temp"]], 
  df4 = dflist_eval_gpp_mod[["temp"]],
  df5 = NULL, #dflist_eval_pmodel_stats[["temp"]],
  evalvar="temp", 
  col=c("black", "black", "black", "red", "red"),
  lty=c(1,3,2,1,1),
  range=rep(FALSE,5),
  ylim=c(0,8),
  filnam="./fig/functionalrel_gam_temp.pdf"
  )
plot_functionalrel( 
  df  = dflist_eval_gpp_obs_NT[["vpd"]], 
  df2 = dflist_eval_gpp_obs_DT[["vpd"]], 
  df3 = dflist_eval_gpp_obs_Ty[["vpd"]], 
  df4 = dflist_eval_gpp_mod[["vpd"]],
  df5 = NULL, #dflist_eval_pmodel_stats[["vpd"]],
  evalvar="vpd", 
  col=c("black", "black", "black", "red","red"),
  lty=c(1,3,2,1,1),
  range=rep(FALSE,5),
  ylim=c(-0.3,8),
  filnam="./fig/functionalrel_gam_vpd.pdf"
  )
plot_functionalrel( 
  df  = dflist_eval_gpp_obs_NT[["soilm"]], 
  df2 = dflist_eval_gpp_obs_DT[["soilm"]], 
  df3 = dflist_eval_gpp_obs_Ty[["soilm"]], 
  df4 = dflist_eval_gpp_mod[["soilm"]],
  df5 = NULL, #dflist_eval_pmodel_stats[["soilm"]],
  evalvar="soilm", 
  col=c("black", "black", "black", "red","red"),
  lty=c(1,3,2,1,1),
  range=rep(FALSE,5),
  ylim=c(0,8),
  filnam="./fig/functionalrel_gam_soilm.pdf"
  )
plot_functionalrel( 
  df  = dflist_eval_gpp_obs_NT[["fapar"]], 
  df2 = dflist_eval_gpp_obs_DT[["fapar"]], 
  df3 = dflist_eval_gpp_obs_Ty[["fapar"]], 
  df4 = dflist_eval_gpp_mod[["fapar"]],
  df5 = NULL, #dflist_eval_pmodel_stats[["fapar"]],
  evalvar="fapar", 
  col=c("black", "black", "black", "red","red"),
  lty=c(1,3,2,1,1),
  range=rep(FALSE,5),
  ylim=c(0,10),
  filnam="./fig/functionalrel_gam_fapar.pdf"
  )
plot_functionalrel( 
  df  = dflist_eval_gpp_obs_NT[["ppfd"]], 
  df2 = dflist_eval_gpp_obs_DT[["ppfd"]], 
  df3 = dflist_eval_gpp_obs_Ty[["ppfd"]], 
  df4 = dflist_eval_gpp_mod[["ppfd"]],
  df5 = NULL, #dflist_eval_pmodel_stats[["ppfd"]],
  evalvar="ppfd", 
  col=c("black", "black", "black", "red","red"),
  lty=c(1,3,2,1,1),
  range=rep(FALSE,5),
  ylim=c(0,10),
  filnam="./fig/functionalrel_gam_ppfd.pdf"
  )
```

There are several points here:

- This mixes responses at different time scales and within/across sites.
- The functional relationships based on the ANN look surprisingly "stiff".
- The data suggests increasing GPP across the whole temperature range, while the P-model simulates a levelling off. This could be related to the prescribed temperature sensitivity of ecosystem respiration for the flux decomposition.
- The response to VPD looks surprisingly not like $\sim1/\sqrt{D}$ in the P-model, but in the observations although the respective equation should force it to look so. Therefore, this must have to do with how the ANNs pick up relationships and the noise and correlation structure in the data.

**OPEN POINT:**

Colin has shown some plots at the ICDC that apparently Trevor produced. They show something similar as I have tried here, but as I remember, there seemed to be much more fine-structure in the functional relationships. **Trevor**, how did you do that? Using GAMs (as I remember you saying once)? I don't understand however, why the ANNs look so "stiff" here...




### Soil temperature: reason for bias?

No clear pattern here.
```{r}
## with daily data
ddf <- out_eval_FULL$gpp$fluxnet2015$data$ddf %>% 
  left_join( dplyr::select( metainfo_Tier1_sites_kgclimate_fluxnet2015, sitename, lat, koeppen_code ), by = "sitename" ) %>%
	mutate( hemisphere = ifelse( lat>0, "north", "south" ),
	        bias = gpp_mod - gpp_obs ) %>% 
  dplyr::filter( koeppen_code %in% c("Cfb", "Dfb") )   # "Dfb"  "Cfb"
with( ddf, LSD::heatscatter( soiltemp_obs_mean, bias ) )
abline( h=0, lty=3 )
with( dplyr::filter(ddf, sitename %in% c("IT-Col", "US-MMS", "DE-Hai", "IT-Ro2", "US-UMB", "CA-Qfo", "FI-Hyy") ),
      LSD::heatscatter( temp_fluxnet2015 - soiltemp_obs_mean, bias ) )
abline( h=0, lty=3 )
## with mean season cycle data
#doydf <- out_eval_FULL$gpp$fluxnet2015$data$meandoydf_byclim %>% 
# 	mutate( bias = mod_mean - obs_mean ) %>% 
#   dplyr::filter( koeppen_code %in% c( "Dfb") )   # "Dfb"  "Cfb"
```


### Values aggregated to X days

Aggregated to longer periods, the performance slightly improves. Here, I aggregated modeled and observational data to 5-days periods.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
modobs_ddf <- plot_modobs_xdaily( out_eval$gpp$fluxnet2015$data$xdf, makepdf=FALSE, xlim=c(0,20), ylim=c(0,20) )
```

- There is a pattern: Many simulated data points in the lower range tend to be too high and too low in the higher range. The lower range overestimation will definitely be improved by emprirical soil moisture, and, if applicable, a low-temperature stress function. The underestimation of values in the upper range raise a more fundamental challenge...
- The fact that the correlation improves when aggregating daily values to 5-daily values might reflect that applying the P-model as a light use efficiency model at the daily time scale violates its basic assumption related to the acclimation time scale. Non-linearities of the light-response curve imply that the ratio of GPP to absorbed light relationship declines with increasing light levels (right?). Day-to-day variations in GPP are mainly driven by light availability (not systematically investigated). Hence, anomalies of daily GPP from its mean seasonal cycle should be larger in the P-model than in the observations. This is the case as the figures below show.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
modobs_anomalies_daily <- plot_modobs_anomalies_daily( out_eval_ORG$data$idvdf, out_eval_ORG$data$idvdf_stats, label = "RED", makepdf=TRUE )
```
Above figure shows the correlation and the distribution of anomalies in daily GPP from the respective mean seasonal cycle in the observations and in simulated values. Note that the blue lines in the first plot are the regression lines of daily anomalies for each site. The fact that their slope is consistently lower than 1, indicates that the day-to-day variability in simulated GPP is higher than in observed GPP. This is also reflected by the histogram in the second plot (note standard deviation values given in the upper left corner).

When plotting the same for values aggregated to 5-day bins, the standard deviation of simulated anomalies declines strongly and is in better agreement with the observations (see histogram), but the correlation analysis doesn't suggest a better performance.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
modobs_anomalies_xdaily <- plot_modobs_anomalies_xdaily( out_eval$data$ixvdf, out_eval$data$ixvdf_stats, makepdf=FALSE)
```

**OPEN POINT:**

Would it be worth exploring this in more detail, e.g. quantifying the relationship between some metric and aggregation level, and 'some metric' being e.g. the standard deviation of anomalies, the *R*$^2$ of obs. vs. mod., or ... ?


### Linear trend

Get linear trend (model, coefficients, and their standard errors).
```{r}
load("data/out_eval_NULL.Rdata")
extract_fitvals <- function(model, nam_predictor){
  tmp <- jtools::summ(model, robust = TRUE) # , confint = TRUE
  # df <- tibble( pval = tmp$coeftable[nam_predictor,]["p"],
  #              estimate = tmp$coeftable[nam_predictor,]["Est."],
  #              estimate_upper = tmp$coeftable[nam_predictor,]["97.5%"],
  #              estimate_lower = tmp$coeftable[nam_predictor,]["2.5%"])
  df <- tibble( pval    = tmp$coeftable[nam_predictor,]["p"],
               estimate = tmp$coeftable[nam_predictor,]["Est."],
               se       = tmp$coeftable[nam_predictor,]["S.E."]) %>% 
        mutate( estimate_upper = estimate + se, estimate_lower = estimate - se )
  return(df)
}
adf_trend <- out_eval_NULL$data$adf %>% 
  ungroup() %>% 
  mutate( validpoint = ifelse( is.na(gpp_obs) | is.na(gpp_mod), FALSE, TRUE ) ) %>% 
  group_by( sitename ) %>% 
  nest() %>%
  mutate( npoints = purrr::map( data, ~sum( .$validpoint ) ) ) %>%
  unnest( npoints ) %>%
  filter( npoints > 4 ) %>%
  mutate( trend_obs = purrr::map( data, ~lm( gpp_obs ~ year, data = . ) ),
          trend_mod = purrr::map( data, ~lm( gpp_mod ~ year, data = . ) ) ) %>% 
  mutate( fitvals_obs = purrr::map( trend_obs, ~extract_fitvals(., "year")),
          fitvals_mod = purrr::map( trend_mod, ~extract_fitvals(., "year")) ) %>% 
  unnest( fitvals_obs, names_sep = "_" ) %>% 
  unnest( fitvals_mod, names_sep = "_" )
```

Plot modelled versus observed trend estimates.
```{r}
gg_trend_scatter <- adf_trend %>% 
  ggplot(aes(x = fitvals_obs_estimate, y = fitvals_mod_estimate)) +
  geom_point(aes(size = npoints), alpha = 0.5) +
  geom_errorbar(aes(ymin = fitvals_mod_estimate_lower, ymax = fitvals_mod_estimate_upper), alpha = 0.5) +
  geom_errorbarh(aes(xmin = fitvals_obs_estimate_lower, xmax = fitvals_obs_estimate_upper), alpha = 0.5) +
  # xlim( c(-100, 100) ) + ylim( c(-50, 70)) +
  geom_abline(intercept=0, slope=1, linetype="dotted") +
  theme_classic() +
  labs( x = expression( paste("Observed GPP trend (g C m"^-2, " yr"^-1, ")" ) ),
        y = expression( paste("Modelled GPP trend (g C m"^-2, " yr"^-1, ")" ) ) ) +
  scale_size_continuous(name = " N years")
gg_trend_scatter
```

Plot histogram of trend values.
```{r}
gg_trend_hist <- adf_trend %>% 
  dplyr::select(sitename, fitvals_obs_estimate, fitvals_mod_estimate) %>% 
  pivot_longer(c(fitvals_obs_estimate, fitvals_mod_estimate), values_to = "slope", names_to = "source") %>% 
  ggplot(aes(x = slope, y = ..count.., fill = source)) +
  geom_histogram(alpha = 0.5, color = "black", binwidth = 10, position="identity") +
  scale_fill_manual(values=c("#999999", "#E69F00"), labels = c("Modelled", "Observed"), name = "") +
  labs( x = expression( paste("GPP trend (g C m"^-2, " yr"^-1, ")" ) ), y = "Count" ) +
  theme_classic()
gg_trend_hist
```

```{r}
library(cowplot)
plot_grid(gg_trend_scatter, gg_trend_hist, labels = "auto", label_size = 12)
ggsave("fig/trend_gpp_fluxnet2015.pdf", width=8, height=4)  
ggsave("fig/trend_gpp_fluxnet2015.png", width=8, height=4)  
```



# Preparing data for sharing

```{r}
## This is what I sent to Paula, 19.2.2019
ddf_DT_fluxnet <- obs_eval_DT$ddf %>% 
                  rename( fpar_modis_spl = fapar )
save(ddf_DT_fluxnet, file = "data/ddf_DT_fluxnet.Rdata")
```






<!-- **OPEN POINT:** -->

<!-- For some sites, this relationship is completely off. I'll have to have a closer look to check if the data is ok. -->

<!-- Selecting data only for sites used in the SI of our submitted manuscript (Figures S14 and S15 [see here](http://rpubs.com/stineb/si_soilm_global)), should give exactly the same figure, but it doesn't (see below). I'll have to look into what's going wrong here (thereby hopefully also resolving the open point mentioned above). -->

```{r, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
library(readr)
library(dplyr)
successcodes <- readr::read_csv( "successcodes.csv" )
do.sites <- dplyr::filter( successcodes, successcode==1 | successcode==2 )$mysitename
plot_modobs_spatial_annual(
  filter( out_eval_ORG$data$meandf, sitename %in% do.sites),
  lm( gpp_obs ~ gpp_mod, data = filter( out_eval_ORG$data$meandf, sitename %in% do.sites) ),
  filter( out_eval_ORG$data$adf_stats, sitename %in% do.sites),
  makepdf=TRUE, label = "SOILM_GLOBAL", xlim=c(0,3000), ylim=c(0,3000) )
```

### Spatial correlation

Comparing the multi-annual mean per site in simulated and observed GPP ($\overline{X}_i$) yields a "spatial correlation".

```{r, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
modobs_spatial <- plot_modobs_spatial( out_eval$data$meandf, makepdf=FALSE )
```

### Annual GPP anomalies

Comparing annual anomalies ($X'_{i,t}$) yields insight into whether the model accurately simulates interannual variability.
```{r, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
modobs_anomalies_annual <- plot_modobs_anomalies_annual( out_eval$data$iavdf, out_eval$data$iavdf_stats, makepdf=FALSE )
```
### Seasonal cycle
The mean seasonal cycle is calculated as the mean by day-of-year (DOY) across multiple years.
$$
\overline{X_{\text{DOY}}} = \frac{1}{N_y} \sum_y X_{\text{DOY},y}
$$
```{r, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
modobs_meandoy <- plot_modobs_meandoy( out_eval_ORG$data$meandoydf, out_eval_ORG$data$meandoydf_stats, makepdf=TRUE, label = "RED" )
modobs_meandoy <- plot_modobs_meandoy( out_eval_NULL$data$meandoydf, out_eval_NULL$data$meandoydf_stats, makepdf=TRUE, label = "NULL", lab1="NULL" )
```




### Monthly values

Anyways, the obvious next aggregation level is monthly, and the correlation increases further to a stunning *R*$^2$ of 0.69.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
modobs_mdf <- plot_modobs_monthly( out_eval$data$mdf, makepdf=FALSE )
```

### Annual values

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE}
modobs_adf <- plot_modobs_annual( out_eval$data$adf, makepdf=FALSE )
```


# Appendix

## Sites table
```{r siteoverview, echo=FALSE, warning=FALSE, message=FALSE}
require(readr, quietly = TRUE)
require(dplyr, quietly = TRUE)
siteinfo <- readr::read_csv("siteinfo_eval.csv") %>%
            mutate( Reference = paste0("[@", sitename ,"]") ) %>%
            mutate( Period = paste0(as.character(year_start), "-", as.character(year_end)) ) %>%
            dplyr::select( -year_start, -year_end )
siteinfo %>%
  dplyr::rename( Site=sitename, Lon.=lon, Lat.=lat, Elevation=elv, Veg.=classid, Clim.=koeppen_code, N = ndailygpp ) %>%
  dplyr::select( Site, Lon., Lat., Period, Veg., Clim., N, Reference ) %>%
  knitr::kable( caption = "Sites used for evaluation. Lon. is longitude, negative values indicate west longitude; Lat. is latitude, positive values indicate north latitude; Veg. is vegetation type: deciduous broadleaf forest (DBF); evergreen broadleaf forest (EBF); evergreen needleleaf forest (ENF); grassland (GRA); mixed deciduous and evergreen needleleaf forest (MF); savanna ecosystem (SAV); shrub ecosystem (SHR); wetland (WET)." )
```


## Mean seasonality by site

Observed values are in black, simulated in red. The solid line in the centre of the shaded range is the mean by day of year (DOY) across multiply years, shaded ranges indicate the minimum and maximum by DOY across years.

```{r, fig.width=7.6, fig.height=7, echo=FALSE, message=FALSE, warning=FALSE}
plot_by_doy_allsites( out_eval$data$meandoydf_stats, makepdf=FALSE )
```

 -->
